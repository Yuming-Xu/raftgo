# 2.8

下载了raft论文

阅读了abstract之后决定跳过section2-4直接到section5的实现部分，原因是看到section3似乎是指出了paxos的缺点之处

决定用go语言来实现，rpc使用grpc

# 2.9

在阅读了5.1，5.2之后发现对其中的一些概念（log、commitIndex、rpc等等）不是足够熟悉，在google后了解了rpc的概念，然而还是不了解log、commitIndex等概念。

姑且还是继续看下去了

# 2.10

终于醒悟过来log、commitIndex等概念可能在前面的section2-4中有提到，决定重新回头再从section2开始看起

# 2.11

算是第一遍把论文看完了

在看第二遍之前决定忽略cluster membership change的第六章（config修改）和关于数据持久化的第七章（snapshot部分）

# 2.12

看完了第二遍，在https://raft.github.io上用那个5节点的图例确认了一下实现的细节（某些case下leader的行动以及log的更新过程）

# 2.13

摸鱼

# 2.14

开始配置环境，因为更新了catalina，xcode也不能用了，在更新brew的时候报了错，花了一段时间，将golang的环境配好了

# 2.15

配置grpc的环境：

直接输入如下命令失败（time-out）：

```
go get google.golang.org/grpc
```

但是之后我发现就算我挂了代理好像也是不成功，才决定用另一条路径（将所有install需要的依赖包全部git clone下来）：

```
# git clone https://github.com/grpc/grpc-go.git $GOPATH/src/google.golang.org/grpc

# git clone https://github.com/golang/net.git $GOPATH/src/golang.org/x/net

# git clone https://github.com/golang/text.git $GOPATH/src/golang.org/x/text

# git clone https://github.com/golang/sys.git $GOPATH/src/golang.org/x/sys

# go get -u github.com/golang/protobuf/{proto,protoc-gen-go}

# git clone https://github.com/google/go-genproto.git $GOPATH/src/google.golang.org/genproto

# cd $GOPATH/src/

# go install google.golang.org/grpc
```

后来又因为家里网烂会发生报错，最后换热点算是安装好了

首先开始了grpc的学习（其实到这里的时候想想配置环境应该一开始就做的，正好同时阅读论文，能够节省时间）

使用了该教程：http://doc.oschina.net/grpc?t=60133

grpc定义了4种结构，想起了在计网实现选择重传实验的时候被tcp流整的人蒙了，还是直接用简单rpc大概是最适合我的

编写好了初版的proto文件之后，又碰到一个问题：

```
虽然按照网上所给的指导安装了，但是protoc命令并没有出现，我在想可能是环境变量的问题，但是暂时找不到加入环境变量的方法，暂时先搁置（23:23了，先歇了）
结果发现是protoc的问题，在阅读了github上的protobuff的要求后发现要求要先装c++版的实现
```

# 2.16

开始编写RPC部分

```
RequestVoteRpc时，什么样的的情况才是up-to-date：
在理解之后比较可靠的是，首先lastTerm大于我们（当前收到RPC的节点）的log的lastTerm（在这里包括在写AppendEntryRpc时有一个其实本质是一样的疑问，为什么lastTerm大就可以，而不是优先考虑log的长度（index）），如果等于的情况下再比较log长度
关于疑问：如果存在一个lastTerm大，但是log长度却短于其他服务器的服务器，那么这个log一定是在这个服务器作为leader的时候创建的，而他又不可能成为leader，因此矛盾

疑问1:
AppendEntryRpc时，考虑到有没有可能一个log比当前服务器短的服务器成为了leader，这样的情况在raft.io上验证后发现是可能的，而这种情况下后面的log必没有被commit，是可以被清除的

疑问2:
存不存在s.simple_raftlog_length > msgSend.logindex && msgSend.logterm == s.simple_raftlog_term[msgSend.logindex]
存在的，已处理
```

这个时候才留下了一个大坑：异步非阻塞要如何处理。。

因为之前没有多少经验，此时才开始想到，是不是一定得用服务流式才能实现异步，考虑把简单rpc改掉

# 2.17

在改掉之前决定先测试实现一下grpc

```
发现一个在grpc教程中没有指出来的问题，所有的函数名、变量名必须得以大写开头（就算你的proto文件不是以大写开头在编译后也会变成大写
```

### 测试1

设计了一个简单的并发server，一个线程每隔5秒报一次时间，一个线程作为监听线程serve请求

### 测试2

两个服务器进行交互，设定一个timer，当timer到点时服务器向对方发送rpc

### 本日的疑问

在设计的raft中可不可能出现appendEntries中的term比我们的周期小：

答，可能，一个candidate收到上一个周期的leader的rpc（虽然我是强行让其timeout的）

### TODO

接下来基本上就是补全几个函数，然后能够实现第一版5个节点的kvstore进行debug测试

# 2.18

异步部分有很多地方需要理清，得缓一缓思考一下

代码基本补全，接下来就是加入一些log性质用来调试的语句以及进行测试

决定把时间拉长以便观察，时间调整为每5秒发送

目前可明确的bug：

当因为某个不确定的的bug出现时导致某个server宕机，使得其他服务器的端口似乎被占用不能连通

发现的但是不知道原因的bug：服务器出现不会超时的奇怪现象

结果发现似乎都是同一个问题，一旦哪个follower给leader发送了为nil的RetMsg，这几个server也就不能正常工作

发现了问题所在:

```
node: 1 :Broadcasting Rpc
node: 1 :sending heartbeat/entryRpc to  5
node: 1 :sending heartbeat to  5
node: 1 :sending heartbeat/entryRpc to  3
node: 1 :sending heartbeat to  3
node: 1 :sending heartbeat/entryRpc to  2
node: 1 :sending heartbeat to  2
node: 1 :sending heartbeat/entryRpc to  4
node: 1 :sending heartbeat to  4
node: 1 handling return
node 4 return: 1
node: 1 handling return
node 3 return: 1
node: 1 handling return
node 2 return: 1
2020/02/18 21:54:04 fail to call: rpc error: code = DeadlineExceeded desc = context deadline exceeded
exit status 1
```

说明是node5忽然出现无法回复的问题，导致返回了nil

现在的问题是会在一段时间后无法工作，怀疑是定时器的原因（排除）

额外加入一个每五秒报一次时的线程，这个线程也崩了

Dial处没有报错，说明是连接上了，但是没有反应

# 2.19

## 今日测试

### 测试1

将main函数的死循环改到一个额外的函数里，main函数里加入一个5秒执行一次的print，测试发现包括main函数也都死掉了，全部没反应

### 测试2

再次使用了test2的两个server发现没有出现这样的事情，考虑到follower实际只允许的几个函数，怀疑是reset了太多次timer的原因，考虑让一个作为主服务器测试一下其他没有timer的情况

注视掉follower的reset函数以及计时器，测试后发现不是reset的问题，仍然会出现follower死掉的现象

### 测试3

减少成三个节点后发现仍然会出现这样的毛病，说明问题还是在别的位置

### 测试4

将rpc的所有代码全部注释掉，仍然会出现问题，说明不是rpc函数的问题

### 测试5

决定将除了main函数以外的线程都注释掉，然后打开server，main函数里开始复读看看效果

经过测试发现没有问题，都运行的好好的，说明问题出现在别处

### 测试6

将server的reset函数打开，在思考可能是计时器的问题

5个server都进入投票但是不执行胜者的情况下能够正常运转

### 测试7

switch函数里的死循环什么都不做，会导致无限循环而被os或其它东西强制叫停，鬼鬼，终于给找到了





终于debug完毕，开始做一些简单的负载/性能测试（自己没怎么做过测试不太懂啊）

# 2.20

将所有的时间参数改为原来的ms量级（本来为了debug改成了s量级）

缺点：

我最开始是以udp的思想来做的，所以所有的服务器之间通信使用的是短连接，很占用带宽

尝试将服务器之间的连接改为长连接

稳定不下来，考虑检查一下投票机制

目前正常

但是我的做法是每30ms发一次Rpc，现在决定将做法修改为一收到client的cmd就broadcast

然后又出bug了：

nextindex会倒减，commit不增加

# 2.21

发现bug的所在，以我现在的做法，是收到消息就发送entryRpc，然后还是定时发送heartbeat/entryRpc，这样的做法会使得heartbeat和entryRpc是乱序的，此时的发送可能是乱序的：

这样的做法会使得更新的index不符（在这之前因为我的heartbeat和entryRpc都是有序发送的，nextindex和matchindex的维护所需要的信息量很少，所以不会出bug）

因此我们需要加入额外的信息（我们传过去的信息里的index）去处理这里

更新完之后这个部分解决了

但是又出现了一个新问题，存在一部分msgapp，不知道跑到哪个语句块，print也没找到

通过插入print检查语句块发现是在checkcommitindex的时候发生了死锁

再插几个print检查一下是哪个锁出现了问题

发现了是自己在follower转发时加上了一个锁导致出现了问题

### 继续开始性能测试

qps一直在50-60左右，很奇怪，找了几个函数都没有影响，考虑是commitIndex的锅

后来发现自己更新commit的位置不太对，进行了修改

最开始我实现的时候是每30ms广播一次及检查一次commit，而我在修改了广播之后并没有修改commit检查的时机，导致速度过慢